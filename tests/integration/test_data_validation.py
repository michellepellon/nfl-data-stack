"""
Data Validation Tests for NFL Data Stack

Tests that validate data quality, schema correctness, and business rules
for Parquet files generated by dbt models.
"""

import pytest
import pandas as pd
import polars as pl
from pathlib import Path


@pytest.mark.integration
class TestParquetSchemas:
    """Test that Parquet files have correct schemas"""

    def test_ratings_parquet_schema(self, data_catalog_dir):
        """Validate nfl_ratings.parquet schema"""
        file_path = data_catalog_dir / "nfl_ratings.parquet"

        if not file_path.exists():
            pytest.skip(f"File not found: {file_path}")

        df = pd.read_parquet(file_path)

        # Required columns
        required_cols = ["team", "conf", "division", "elo_rating", "ingested_at"]
        for col in required_cols:
            assert col in df.columns, f"Missing required column: {col}"

        # Data types
        assert df["team"].dtype == "object", "team should be string"
        assert df["conf"].dtype == "object", "conf should be string"
        assert df["division"].dtype == "object", "division should be string"
        assert pd.api.types.is_numeric_dtype(df["elo_rating"]), "elo_rating should be numeric"

    def test_simulator_parquet_schema(self, data_catalog_dir):
        """Validate nfl_reg_season_simulator.parquet schema"""
        file_path = data_catalog_dir / "nfl_reg_season_simulator.parquet"

        if not file_path.exists():
            pytest.skip(f"File not found: {file_path}")

        df = pd.read_parquet(file_path)

        # Required columns
        required_cols = [
            "scenario_id", "game_id", "week_number",
            "home_team", "visiting_team", "winning_team",
            "home_team_elo_rating", "visiting_team_elo_rating",
            "home_team_win_probability"
        ]
        for col in required_cols:
            assert col in df.columns, f"Missing required column: {col}"

        # Check win probability is in basis points (0-10000)
        assert df["home_team_win_probability"].min() >= 0, "Win prob should be >= 0"
        assert df["home_team_win_probability"].max() <= 10000, "Win prob should be <= 10000"

    def test_playoff_probabilities_schema(self, data_catalog_dir):
        """Validate nfl_playoff_probabilities_ci.parquet schema"""
        file_path = data_catalog_dir / "nfl_playoff_probabilities_ci.parquet"

        if not file_path.exists():
            pytest.skip(f"File not found: {file_path}")

        df = pd.read_parquet(file_path)

        # Required columns
        required_cols = [
            "team", "playoff_prob_pct", "playoff_ci_lower_pct", "playoff_ci_upper_pct",
            "avg_wins", "wins_ci_lower", "wins_ci_upper"
        ]
        for col in required_cols:
            assert col in df.columns, f"Missing required column: {col}"


@pytest.mark.integration
class TestDataQualityRules:
    """Test business rules and data quality constraints"""

    def test_elo_ratings_in_valid_range(self, data_catalog_dir):
        """ELO ratings should be between 1000-2000 for NFL teams"""
        file_path = data_catalog_dir / "nfl_ratings.parquet"

        if not file_path.exists():
            pytest.skip(f"File not found: {file_path}")

        df = pd.read_parquet(file_path)

        # NFL ELO ratings typically 1300-1700, allow 1000-2000 for outliers
        assert df["elo_rating"].min() >= 1000, "ELO rating too low (< 1000)"
        assert df["elo_rating"].max() <= 2000, "ELO rating too high (> 2000)"
        assert df["elo_rating"].notna().all(), "ELO ratings should not be null"

    def test_win_probabilities_sum_to_100(self, data_catalog_dir):
        """Home and away win probabilities should sum to 100% (basis points: 10000)"""
        file_path = data_catalog_dir / "nfl_reg_season_simulator.parquet"

        if not file_path.exists():
            pytest.skip(f"File not found: {file_path}")

        df = pd.read_parquet(file_path)

        # home_team_win_probability is in basis points (0-10000)
        # visiting_team_win_probability = 10000 - home_team_win_probability
        visiting_prob = 10000 - df["home_team_win_probability"]

        # All probabilities should be between 0-10000
        assert (df["home_team_win_probability"] >= 0).all(), "Home win prob should be >= 0"
        assert (df["home_team_win_probability"] <= 10000).all(), "Home win prob should be <= 10000"
        assert (visiting_prob >= 0).all(), "Visiting win prob should be >= 0"
        assert (visiting_prob <= 10000).all(), "Visiting win prob should be <= 10000"

    def test_confidence_intervals_valid(self, data_catalog_dir):
        """Confidence intervals should be valid (lower < point estimate < upper)"""
        file_path = data_catalog_dir / "nfl_playoff_probabilities_ci.parquet"

        if not file_path.exists():
            pytest.skip(f"File not found: {file_path}")

        df = pd.read_parquet(file_path)

        # Playoff probability CIs
        assert (df["playoff_ci_lower_pct"] <= df["playoff_prob_pct"]).all(), \
            "Playoff CI lower bound should be <= point estimate"
        assert (df["playoff_prob_pct"] <= df["playoff_ci_upper_pct"]).all(), \
            "Playoff CI upper bound should be >= point estimate"

        # Win CIs
        assert (df["wins_ci_lower"] <= df["avg_wins"]).all(), \
            "Wins CI lower bound should be <= point estimate"
        assert (df["avg_wins"] <= df["wins_ci_upper"]).all(), \
            "Wins CI upper bound should be >= point estimate"

    def test_all_teams_present(self, data_catalog_dir):
        """All 32 NFL teams should be present in ratings"""
        file_path = data_catalog_dir / "nfl_ratings.parquet"

        if not file_path.exists():
            pytest.skip(f"File not found: {file_path}")

        df = pd.read_parquet(file_path)

        # Should have 32 teams (allow 33 for legacy team names like "Washington Football Team")
        # In production, this would be a data quality issue to fix
        assert 32 <= len(df) <= 33, \
            f"Should have 32-33 NFL teams (allowing legacy names), found {len(df)}"

        # Check for specific duplicates (Washington rebranding)
        if len(df) == 33:
            washington_teams = df[df["team"].str.contains("Washington", case=False)]
            if len(washington_teams) > 1:
                pytest.xfail("Found duplicate Washington team names (legacy data)")

        # Team names should be unique
        assert df["team"].is_unique, "Team names should be unique"

    def test_week_numbers_valid(self, data_catalog_dir):
        """Week numbers should be 1-18 for regular season"""
        file_path = data_catalog_dir / "nfl_reg_season_simulator.parquet"

        if not file_path.exists():
            pytest.skip(f"File not found: {file_path}")

        df = pd.read_parquet(file_path)

        assert df["week_number"].min() >= 1, "Week number should be >= 1"
        assert df["week_number"].max() <= 18, "Week number should be <= 18 (regular season)"

    def test_no_null_critical_fields(self, data_catalog_dir):
        """Critical fields should not have null values"""
        file_path = data_catalog_dir / "nfl_reg_season_simulator.parquet"

        if not file_path.exists():
            pytest.skip(f"File not found: {file_path}")

        df = pd.read_parquet(file_path)

        critical_fields = [
            "scenario_id", "game_id", "home_team", "visiting_team",
            "winning_team", "home_team_elo_rating", "visiting_team_elo_rating"
        ]

        for field in critical_fields:
            assert df[field].notna().all(), f"Field {field} should not have nulls"


@pytest.mark.integration
@pytest.mark.slow
class TestDataFreshness:
    """Test that data is fresh (recent ingestion timestamps)"""

    def test_ratings_freshness(self, data_catalog_dir):
        """Ratings should be recently updated (within last 7 days)"""
        file_path = data_catalog_dir / "nfl_ratings.parquet"

        if not file_path.exists():
            pytest.skip(f"File not found: {file_path}")

        df = pd.read_parquet(file_path)

        if "ingested_at" not in df.columns:
            pytest.skip("No ingested_at column found")

        # Convert to datetime
        df["ingested_at"] = pd.to_datetime(df["ingested_at"])
        latest_ingestion = df["ingested_at"].max()

        from datetime import datetime, timedelta, timezone
        now = datetime.now(timezone.utc)  # Use timezone-aware datetime
        week_ago = now - timedelta(days=7)

        # Make latest_ingestion timezone-aware if it isn't already
        if latest_ingestion.tzinfo is None:
            latest_ingestion = latest_ingestion.replace(tzinfo=timezone.utc)

        # Allow data to be up to 7 days old (for manual testing)
        # In production, this should be much stricter (e.g., 24 hours)
        assert latest_ingestion > week_ago, \
            f"Data is stale (last updated: {latest_ingestion}, now: {now})"


@pytest.mark.integration
class TestEloRollforwardOutput:
    """Test ELO rollforward model outputs"""

    def test_elo_rollforward_has_all_games(self, data_catalog_dir):
        """ELO rollforward should have one row per completed game"""
        file_path = data_catalog_dir / "nfl_elo_rollforward.parquet"

        if not file_path.exists():
            pytest.skip(f"File not found: {file_path}")

        df = pd.read_parquet(file_path)

        # Should have game_id column
        assert "game_id" in df.columns
        assert "elo_change" in df.columns
        assert "home_team_elo_rating" in df.columns
        assert "visiting_team_elo_rating" in df.columns

        # game_id should be unique
        assert df["game_id"].is_unique, "game_id should be unique"

    def test_elo_changes_reasonable(self, data_catalog_dir):
        """ELO changes should be reasonable magnitude"""
        file_path = data_catalog_dir / "nfl_elo_rollforward.parquet"

        if not file_path.exists():
            pytest.skip(f"File not found: {file_path}")

        df = pd.read_parquet(file_path)

        # With K=20 and MOV multiplier, ELO changes should be < 100
        # (extreme blowout upsets might be ~50-70, normal games ~10-20)
        assert df["elo_change"].abs().max() < 100, \
            "ELO changes should be < 100 for normal games"

        # No null ELO changes
        assert df["elo_change"].notna().all(), "ELO changes should not be null"
